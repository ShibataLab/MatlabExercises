%% Shibata Lab Workshops, 2015/5/2

% Machine Learning 101 Workshop
% ex3: computeCost

% In this exercise you will implement the cost function J()
% for gradient descent algorithm. Write your code in the
% this file where it is indicated

function J = computeCost(X, y, theta)

% Initializing number of samples
m = length(y);

% Initializing cost variable which will be returned
J = 0;

%=======================YOUR CODE HERE======================
% Instructions: Compute the cost for a particular theta. The
% cost should be assigned to J.

%===========================================================

end
