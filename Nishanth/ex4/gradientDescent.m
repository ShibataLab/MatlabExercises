%% Shibata Lab Workshops, 2015/5/2

% Machine Learning 101 Workshop
% ex4: gradientDescent

% In this exercise you will implement the gradient descent J()
% algorithm. Write your code in this file where it is indicated.

function theta = gradientDescent(X, y, theta, alpha, iterations)

% Initializing number of samples
m = length(y);

% Performing cost update in for loop
for iter = 1:iterations

    %=======================YOUR CODE HERE======================
    % Instructions: Perform a single update of theta using gradient
    % descent algorithm.
    
    %===========================================================

end

end
